###  knn
K近邻算法的原理非常简单：对于一个新样本，K近邻算法的目的就是在已有数据中寻找与它最相似的K个数据，
或者说“离它最近”的K个数据，如果这K个数据大多数属于某个类别，则该样本也属于这个类别。


距离：
欧式距离: $ \sqrt((x_{11}-x_{12})^2 + (x_{21}-x_{22})^2) $
n维: $ \sqrt((x_{11}-x_{12})^2 + (x_{21}-x_{22})^2 + \cdots +(x_{n1}-x_{n2})^2) $

```python
# 手写

# sklearn
```


##### 问题一：由于是两两计算，那么n个点的距离，一共需要计算$(n-1)(n-2)\cdots1$次？
##### 问题二：由原理可知，更改K的数值，会改变部分预测，如何判断最优？