首先最基本的是将数据集分为训练集(Training)与测试集(Test)两部分。
在测试集用于训练、确定一个最终的模型；
然后在测试集测试模型对于未知数据的评价效果。

1.1 训练集
如上所述，在训练集就要确定了最终的模型，包括参数优化；
一般来说原始Train训练集会进一步再分为Train训练集与Validation验证集两部分，以评价不同参数组合的效果，以确定最终的模型。最后放到Test测试集中评价其效果。
1.2 测试集
一定要注意Test测试集自始至终没有参与到模型的训练过程；它的目的只有一个：在确定一个最终模型后，评价其泛化能力。
1.3 拆分方法
一般先拆分数据为（Train + Validation）与Test两部分，其比例一般为 8:2、7:3、6:4
其次进一步拆分出Train + Validation的方法：可以按照设定比例进行拆分，也有K折交叉验证☆、Bootstrap自助法抽样。
（1）K折交叉验证
K折交叉验证是比较常用的拆分训练集、测试集，并用于模型训练、验证的方式。具体步骤如下--

首先将原始训练集(区别test测试集数据)分为K份；
然后选择其中K-1 份数据用于训练，剩余的1份用于评价效果；
重复K次，保证每份数据都作为过训练数据与验证数据；
最后得到K次的模型评价结果；取均值作为该模型参数下的最终评价结果；
从而可以比较不同模型参数下的评价结果，进行模型优化，确定最终的模型。

（2）Bootstrapping自助法抽样
自助法抽样的核心理解就是：有放回的抽样。
因为有放回，所以可能会抽到重复值；据统计计算会抽到63.21%的数据，
而未被抽到过的数据(out-of-bag, OOB)则被视为validation验证集。

考虑一个特定的小球A，每次抽样A被抽到的概率为1/100，A没有被抽到的概率为1 － 1/100，则经过100次抽样，A没有被抽到的概率 P ＝(1 － 1/100) ^ 100

当样本个数不是100，而是非常大的数的时候（比如为x，x非常大），A没有被抽到的概率 P＝(1 - 1/x) ^ x
当x趋于无穷时（1+1/(1+x))^x= e

再强调一点就是：是将原始训练集进一步拆分为 训练集与测试集。
在上述过程中，都是把测试集放到一边的，不去管它，直到确定好模型之后才会用到test测试集。


